\documentclass[12pt]{article}
\usepackage{float}
%\usepackage[ruled,vlined,linesnumbered,algo2e]{algorithm2e}
\usepackage{amsmath,amssymb}
\usepackage{amsthm}
\usepackage{makecell}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}

\usepackage{pgfplots}
% and optionally (as of Pgfplots 1.3):
\pgfplotsset{compat=newest}
\pgfplotsset{plot coordinates/math parser=false}
\newlength\figureheight
\newlength\figurewidth


\usepackage[a4paper, total={6.5in, 9in}]{geometry}
\usepackage{tikz}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
   \node[shape=circle,draw=red,inner sep=1pt] (char) {#1};}}
\setlength\parindent{0pt} %% Do not touch this
\DeclareMathOperator{\phiAb}{\phi_{A,\mathbf{b}}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
%% -----------------------------
%% TITLE
%% -----------------------------
\title{Short review of different beamforming techniques for passive array processing} %% Assignment Title
\author{Wissal Ghamour, Julien Gleyze and Nathan Rousselot}
%% Change "\today" by another date manually
%% -----------------------------
%% -----------------------------

%% %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%\setlength{\droptitle}{-5em}    
%% %%%%%%%%%%%%%%%%%%%%%%%%%
\maketitle
% --------------------------
% Start here
% --------------------------
\section{Introduction}
In this document, we will cover a range of techniques specific to array processing. Array processing is a branch of signal processing dedicated to the processing of signals produced or received by an array of elements. Those element can be antennas in passive setups, or transducers in the context of radar or sonar processing. In the following, we will focus on the passive setup, meaning we work with an array of sensors. This class of problem has a wide range of applications, from radio astronomy to wireless communications. All those applications share common challenges, such as the estimation of the direction of arrival (DOA) of a signal, or optimizing the Signal-to-Interference-plus-Noise ratio (SINR). In this introductory document, we will focus ourselves on the impact of the choice of beamforming techniques, ranging from Conventional Beamforming to more robust and adaptative methods.
\section{Direct Methods}
Consider the following signal
\begin{equation}\label{eq:signal}
   \mathbf{y}(k) = \mathbf{a}_ss(k) + \mathbf{y}_{I}(k) + \mathbf{n}(k)
\end{equation}
where $\mathbf{a}_s$ is the steering vector of the signal of interest, $s(k)$ is the signal of interest, $\mathbf{y}_{I}(k)$ is the interference signal, and $\mathbf{n}(k)$ is the noise. In this section, it is assumed that $\mathbf{a}_s$ is perfectly known, meaning $\mathbf{a}_0 = \mathbf{a}_s$. The goal of beamforming is to find a weight vector $\mathbf{w}$ such that the output of the beamformer $\hat{s}(k)$ is a good estimate of $s(k)$. The output of the beamformer is given by
\begin{equation}\label{eq:bf}
   \hat{s}(k) = \mathbf{w}^H\mathbf{y}(k)
\end{equation}
\subsection{Conventional Beamformer}
The conventional beamformer is the simplest beamformer. It is defined as
\begin{equation}\label{eq:cbf}
   \mathbf{w}_{CBF} \propto \mathbf{a}(\theta_s)
\end{equation}
\begin{theorem}
    Let $\mathbf{y}(k)$ be defined by equation \ref{eq:signal} and $\mathbf{w}$ the weight vector. Considering $\mathbf{a}^H(\theta_s)\mathbf{a}(\theta_s)$ is non-singular, the coefficients of $\mathbf{w}$ that maximize the gain at $\theta_s$, subject to equation \ref{eq:cbf} is given by
    \begin{equation}
        \mathbf{w}_{CBF} = \left(\mathbf{a}^H(\theta_s)\mathbf{a}(\theta_s)\right)^{-1}\mathbf{a}(\theta_s)
    \end{equation}
\end{theorem}
\begin{proof}

\end{proof}
This beamformer is optimal when there is no-noise, and no-interference. In the vast majority of applications, this is obviously not the case. 
\subsection{Optimal Adaptative Beamformer}\label{sec:opt}
In actual conditions, CBF will prove itself as very sub-optimal. In this section we will introduce a new beamformer, that is deemed and called ``optimal''. It accounts for interferences and noise, thus fitting the model depicted in equation \ref{eq:signal}. Let us formulate this as an optimization problem. Let $\mathbf{w}\in\mathcal{W}$, the weight vector, then
\begin{equation}
    \mathbf{w}_{opt} = \max_{w\in\mathcal{W}}  \text{ SINR}(\mathbf{w})
\end{equation}
\begin{theorem}\label{thm:wopt}
    Let $\mathbf{y}(k)$ be defined following equation \ref{eq:signal} of length N. Assuming that $\forall k, \lambda_k(\mathbf{y}_I(k)+\mathbf{n}(k)) \neq 0$, with $\lambda_k(\mathbf{A})$ eigenvalues of $\mathbf{A}$, then 
    \begin{equation}\label{eq:wopt}
        \mathbf{w}_{opt} = \frac{\mathbf{C}^{-1}\mathbf{a}_s}{\mathbf{a}_s^H\mathbf{C}^{-1}\mathbf{a}_s}
    \end{equation}
\end{theorem}
\begin{proof}
From equations \ref{eq:signal} and \ref{eq:bf}, one can rewrite the output of the beamformer as
\begin{equation*}\label{eq:new_signal}
   \hat{s}(k) = \mathbf{w}^H\mathbf{a}_ss(k) + \mathbf{w}^H\mathbf{y}_{I}(k) + \mathbf{w}^H\mathbf{n}_k
\end{equation*}
\begin{equation*}
    \Rightarrow \text{ SINR}(\mathbf{w}) = \frac{\mathbb{E}\left[|\mathbf{w}^H\mathbf{a}_ss(k)|^2\right]}{\mathbb{E}\left[|\mathbf{w}^H\mathbf{y}_{I}(k) + \mathbf{w}^H\mathbf{n}(k)|^2\right]} = \frac{P_s|\mathbf{w}^H\mathbf{a}_s|^2}{\mathbf{w}^H\mathbf{C}\mathbf{w}}
\end{equation*}
Where $\mathbf{C}$ is the noise plus interference covariance matrix.
It is assumed that $\forall k, \lambda_k(\mathbf{C})\neq 0$. Thus, equation \ref{eq:wopt} rewrites
\begin{equation*}
    \mathbf{w}_{opt} = \max_{w\in\mathcal{W}} \frac{P_s|\mathbf{w}^H\mathbf{a}_s|^2}{\mathbf{w}^H\mathbf{C}\mathbf{w}}
\end{equation*}
For practical reason, let us constrain the gain to be unit
$$\begin{aligned}
    \mathbf{w}_{opt} =& \max_{w\in\mathcal{W}} &\frac{P_s|\mathbf{w}^H\mathbf{a}_s|^2}{\mathbf{w}^H\mathbf{C}\mathbf{w}}\\
    & \textrm{s.t.} \quad &|\mathbf{w}^H\mathbf{a}_s| = 1
\end{aligned} \Longleftrightarrow \begin{aligned}
    \mathbf{w}_{opt} =& \max_{w\in\mathcal{W}} &\frac{P_s}{\mathbf{w}^H\mathbf{C}\mathbf{w}}\\
    & \textrm{s.t.} \quad &|\mathbf{w}^H\mathbf{a}_s| = 1
\end{aligned}$$
Which yiels the following optimization problem
$$\begin{aligned}
    \mathbf{w}_{opt} =& \min_{w\in\mathcal{W}} &\mathbf{w}^H\mathbf{C}\mathbf{w}\\
    & \textrm{s.t.} \quad &|\mathbf{w}^H\mathbf{a}_s| = 1
\end{aligned}$$
\end{proof}
% %%%%%%%%%%%%%%%%%%%
\section{Practical Adaptative Beamforming Techniques}
In reality, the optimal beamformer (section \ref{sec:opt}) is very unpractical. Indeed, in actual conditions, the steering vector $\mathbf{a}_s$ and the covariance matrix $\mathbf{C}$ are unknown. Instead, we have approximates, respectively $\mathbf{a}_0$ and $\hat{\mathbf{C}}$.
\subsection{Minimum Variance Distortionless Response}
The Minimum Variance Distortionless Responsor (MVDR) is the direct consequence of the optimal beamformer (section \ref{sec:opt}) with approximated entries. It thus writes automatically
\begin{equation}\label{eq:mvdr}
    \mathbf{w}_{mvdr}^{smi} = \frac{\hat{\mathbf{C}}^{-1}\mathbf{a}_0}{\mathbf{a}_0^H\hat{\mathbf{C}}^{-1}\mathbf{a}_0}
\end{equation}
where $smi$ stands for ``sample matrix inversion'' and is directly linked to how $\hat{\mathbf{C}}$ is being approximated (equation \ref{eq:chat}).
\begin{equation}\label{eq:chat}
    \hat{\mathbf{C}} = \frac{1}{K}\sum_{k=1}^K \mathbf{y}(k)\mathbf{y}^H(k)
\end{equation}
where $\mathbf{y}(k) = \mathbf{y}_I(k)+\mathbf{n}(k)$
\subsection{Minimum Power Distortionless Response}
\subsubsection{Naive Approach}
Sometimes, it is not possible to isolate the noise and the interference to estimate $\mathbf{C}$. Leading us to the Minimum Power Distortionless Response beamformer (MPDR).
\begin{equation}\label{eq:mpdr}
    \mathbf{w}_{mpdr}^{smi} = \frac{\hat{\mathbf{R}}^{-1}\mathbf{a}_0}{\mathbf{a}_0^H\hat{\mathbf{R}}^{-1}\mathbf{a}_0}
\end{equation}

\begin{equation}\label{eq:mpdr_chat}
    \hat{\mathbf{R}} = \frac{1}{K}\sum_{k=1}^K \mathbf{y}(k)\mathbf{y}^H(k)
\end{equation}
where $\mathbf{y}(k) = \mathbf{a}_ss(k) + \mathbf{y}_I(k)+\mathbf{n}(k)$. Intuitively, one can think that adding the signal information to the covariance matrix will lead to signal degradation as we want to minimize its output power. 
\begin{lemma}\label{lem:mpdr}
    In case where $K\rightarrow\infty$ and $\mathbf{a}_0 = \mathbf{a}_s$, then the beam patterns of MVDR and MPDR are identical.
\end{lemma}
\begin{proof}
    Recall from equation \ref{eq:bf}
    \begin{equation*}
        \hat{s}(k)=\mathbf{w}^H\mathbf{a}_ss(k) + \mathbf{w}^H\mathbf{y}_I(k) + \mathbf{w}^H\mathbf{n}(k)
    \end{equation*}
    Now recall from Theorem \ref{thm:wopt} 
    $$\begin{aligned}
    \mathbf{w} =& \min_{w\in\mathcal{W}} &\mathbf{w}^H\mathbf{C}\mathbf{w}\\
    & \textrm{s.t.} \quad &|\mathbf{w}^H\mathbf{a}_s| = 1
\end{aligned}$$
    The constraint $|\mathbf{w}^H\mathbf{a}_s| = 1$ then ensures that the part of $\hat{s(k)}$ with the signal of interest will be preserved.
\end{proof}
In lemma \ref{lem:mpdr}, we demonstrated that MPDR and MVDR are equivalent mathematically, even while having different formulations. However, it is based uppon two strong assumptions, that are, in practice, very unrealistic. We will analyze the impact of releasing the constraint on $K$ and on $\mathbf{a_0}$ seperately.

Figure \ref{fig:mpdr_robust} illustrate the lack of robustness in MPDR method, with respect to error in the direction of arrival estimation $\Delta\theta$. It shows from figure \ref{fig:mpdr_robus_sinr} that the resulting SINR with MPDR is greatly suboptimal as soon as $\Delta\theta$ increases a bit. Looking at the array white noise gain $A_{WN}$ (figure \ref{fig:mpdr_robus_awn}, we observe that this gain dramatically decreases as $\Delta\theta$ increases. Recall that 
\begin{equation}
    A_{WN} = \|w\|^{-2} \leq N
\end{equation}
Ideally, we would want $A_{WN}=N$, and thus the pattern drawn in figure \ref{fig:mpdr_robus_awn} is worrying.
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{.4\linewidth}
        \input{paper/figures/mpdr_sinr_not_robust}
        \caption{SINR vs error in $\mathbf{a}_0$}
        \label{fig:mpdr_robus_sinr}
    \end{subfigure}\hspace{0.09\linewidth}
    \begin{subfigure}[b]{.4\linewidth}
        \input{paper/figures/mpdr_awn_not_robust}
        \caption{$A_{WN}$ vs error in $\mathbf{a}_0$}
        \label{fig:mpdr_robus_awn}
    \end{subfigure}
    \caption{Measure of robustness of MVDR and MPDR in function of the error in the direction of arrival estimation.}
    \label{fig:mpdr_robust}
\end{figure}
In figure \ref{fig:mpdr_robust} we assumed that $\mathbf{C}$ and $\mathbf{R}$ were exactly known, \textit{i.e} $K\rightarrow\infty$. As $K$ is the number of snapshots used to estimate $\mathbf{C}$ and $\mathbf{R}$, one can easily guess why it is a bold assumption. Let us assume that $\mathbf{a}_0$ is perfectly known, and then let us study the convergence properties of MVDR and MPDR beamformers in function of K.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{.4\linewidth}
        \input{paper/figures/robust_k_sinr}
        \caption{SINR in function of K}
        \label{fig:robust_k_sinr}
    \end{subfigure}\hspace{0.09\linewidth}
    \begin{subfigure}[b]{.4\linewidth}
        \input{paper/figures/robust_k_awn}
        \caption{$A_{WN}$ in function of K}
        \label{fig:robust_k_awn}
    \end{subfigure}
    \caption{Convergence in function of K of MVDR and MPDR.}
    \label{fig:mpdr_robust}
\end{figure}

It appears from both figures \ref{fig:robust_k_sinr} and \ref{fig:robust_k_awn} that MPDR requires way more snapshots than MVDR to converge. To understand where this lack of performance of MPDR comes from, figure \ref{fig:poor_mvdr_beampattern} gives a hint. Recall from equation \ref{eq:mpdr_chat} that the covariance matrix in the MPDR beamformer contains the signal of interest. Now, from equation \ref{eq:mpdr}, we recall that the optimization problem with respect to this covariance matrix tends to add zeros to the respective components (usually, the interferences) of the covariance matrix. When there is a significant error in the distance of arrival estimation, as illustrated in figure \ref{fig:poor_mvdr_beampattern}, then, the MPDR beamformer will naturally consider the signal of interest as interference, and put a zero where it is coming from. This explains why MPDR, as seen so far, is lacking a lot of robustness, and cannot be used in practice.

\begin{figure}[H]
    \centering
    \input{paper/figures/poor_mvdr_beampattern}
    \caption{Beampatterns comparison between MVDR, MPDR, CBF and Optimal bemformers. We can observe the zero that has been set right in the direction of arrival of MPDR, thus creating the loss in SINR/$A_{WN}$}
    \label{fig:poor_mvdr_beampattern}
\end{figure}
\subsubsection{Robust MPDR}
From the previous section, it seems that MPDR is hardly usable in practice. However, while MVDR is seemingly a better option, it requires being able to measure the noise plus interference covariance matrix, without the signal of interest. This can be the case, for example, in radio-astronomy. We need to find tricks that enables the use of MPDR. In this section, we demonstrate that by constraining the $A_{WN}$ gain to be above a certain threshold, close to $N$, we can robustify MPDR. This means we want to solve 
$$\begin{aligned}
    \mathbf{w}_{mpdr} =& \min_{w\in\mathcal{W}} &\mathbf{w}^H\mathbf{C}\mathbf{w}\\
    & \textrm{s.t.} \quad &|\mathbf{w}^H\mathbf{a}_s| = 1\\
    & \textrm{s.t.} \quad &\|w\|^{-2} \geq \alpha N
\end{aligned}$$
where $\alpha$ is a constant. This optimization problem is a Quadratically Constrained Quadratic Program (QCQP). It can be solved using the Lagrangian method. The Lagrangian of this problem is given by
\begin{equation}
    \mathcal{L}(\mathbf{w},\lambda,\mu) = \mathbf{w}^H\mathbf{C}\mathbf{w} + \lambda\left(|\mathbf{w}^H\mathbf{a}_s| - 1\right) + \mu\left(\|w\|^{-2} - \alpha N\right)
\end{equation}
where $\lambda$ and $\mu$ are the Lagrange multipliers. After some simplifications, and by enforcing $\mathbf{w}^H\mathbf{a}_0 = 1$, we get
\begin{equation}\label{eq:mpdr_dl}
    \mathbf{w}_{MPDR-DL} = \frac{\left(\hat{\mathbf{R}}+\mu \mathbf{I}\right)^{-1}\mathbf{a}_0}{\mathbf{a}_0^H\left(\hat{\mathbf{R}}+\mu \mathbf{I}\right)^{-1}\mathbf{a}_0}
\end{equation}
We can note that when $\mu = 0$, we get the naive MPDR beamformer. When $\mu\rightarrow\infty$ we get the CBF beamformer. We thus showed that this new constraied method is, in fact, a matter of compromise between MPDR and CBF. Figure \ref{fig:MPDR_robust} shows the robustness of this new method, with respect to the error in the direction of arrival estimation. We can observe that the SINR is greatly improved, and that the $A_{WN}$ is close to $N$.
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{.4\linewidth}
        \input{paper/figures/MPDR_robust_sinr}
        \caption{SINR in function of $\Delta\theta$}
        \label{fig:MPDR_robust_sinr}
    \end{subfigure}\hspace{0.09\linewidth}
    \begin{subfigure}[b]{.4\linewidth}
        \input{paper/figures/MPDR_robust_awn}
        \caption{$A_{WN}$ in function of $\Delta\theta$}
        \label{fig:MPDR_robust_awn}
    \end{subfigure}
    \caption{Robustness of the new MPDR method in function of the error in the direction of arrival estimation.}
    \label{fig:MPDR_robust}
\end{figure}
Looking at the rate of convergence of this new method, we can observe that it is similar to the one of MVDR, as shown in figure \ref{fig:robust_k_sinr} and \ref{fig:robust_k_awn}. This is a good news, as it means that we can use this new method in practice, and that it is not too sensitive to the number of snapshots used to estimate $\mathbf{R}$.
\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.4\linewidth}
        \input{paper/figures/MPDR_robust_awn_k}
        \caption{SINR in function of K}
        \label{fig:robust_k_sinr}
    \end{subfigure}\hspace{0.09\linewidth}
    \begin{subfigure}[b]{0.4\linewidth}
        \input{paper/figures/MPDR_robust_awn_k}
        \caption{$A_{WN}$ in function of K}
        \label{fig:robust_k_awn}
    \end{subfigure}
    \caption{Convergence in function of K of MVDR and MPDR.}
    \label{fig:mpdr_robust_k}
\end{figure}
An issue with that method is that it requires to know the optimal value of $\mu$, which can be hard in practice as its closed form solution is very hard (close to impossible) to determine. It needs to be done iteratively, and its form is depicted in figure \ref{fig:mu}. 
\begin{figure}[H]
    \centering
    \input{figures/mu_opt}
    \caption{Value of $SINR$ in function of $\mu$}
    \label{fig:mu}
\end{figure}
Figure \ref{fig:mu} shows that, while it is iteratively hard to determine the optimal $\mu$, it seems like this optimum value is not very sensitive, and a gross guess around it should provide with very good (enough) results. 
\subsubsection{Unit-Circle MPDR}
In this section, we will study another approach in making MPDR a robust beamformer. This time, we will take a radically different approach, which does not have any hyperparameter to tune. First, let us consider a vector $\mathbf{w}$. Its associated polynomial is given by
\begin{equation}
    P(z)=\sum_{n=1}^N \mathbf{w}(n)z^{-n}
\end{equation}
An interesting fact, is that for $\mathbf{w}_{opt}$, all the zeroes of $P_{opt}(z)$ are on the unit-circle. In figure \ref{fig:uc_monte_carlo}, we see that throughout 1000 Monte-Carlo samples, while it seems that the average values of the zeroes of $P_{MPDR-SMI}(z)$ are on the unit circle, in practice, very few of them actually are. Algorithm 1 is a proposition to enable the calculation of unit-circle corrected weight. In figure \ref{fig:uc_corrected}, we notice that we indeed have corrected the weights, and they now belong to the unit-circle. Beware, in algorithm 1, to lines 5-8. They seem a bit ``heuristic'' put up this way, though they ensure that no zeroes are put in the main lobe, which would be catastrophic for the resulting weights.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.4\linewidth}
        \includegraphics[width=.9\linewidth]{paper/figures/uc_monte_carlo.pdf}
        \caption{Monte Carlo Sampling}
        \label{fig:uc_monte_carlo}
    \end{subfigure}\hspace{0.09\linewidth}
    \begin{subfigure}[b]{0.4\linewidth}
        \includegraphics[width=.9\linewidth]{paper/figures/uc_corrected.pdf}
        \caption{Correction of zeroes}
        \label{fig:uc_corrected}
    \end{subfigure}
    \caption{Unit Circle zeroes correction}
    \label{fig:mpdr_robust_k}
\end{figure}

\begin{algorithm}
\caption{Unit Circle MPDR weight algorithm}

\KwIn{Matrix $L$, vector $x$, vector $v_0$, scalar $N$, scalar $Q$, scalar $P$}
\KwOut{MVDR weights $w_{SMI}$ and $w_{UC}$, unit circle polynomial $P_{UC}(z)$}

% Step 1: Compute SCM
Compute SCM: $R = \frac{1}{K} \sum_{n=1}^{N} xx^H$\;

% Step 2: Compute SMI MVDR weights
Compute SMI MPDR weights: $w_{SMI} = \frac{R^{-1}a_0}{a_0^H R^{-1} a_0}$\;

% Step 3: Compute PS(z)
Compute $PS(z) = P_{SMI}(z) = \prod_{n=1}^{Q-1} (1 - \xi_n z^{-1})$ where $\xi_n = r_n e^{j\omega_n}$\;

% Step 4-8: Conditions on omega_n and xi_n
\For{$n=1$ \KwTo $Q-1$}{
    \eIf{$|\omega_n| > \frac{2\pi}{N}$}{
        $\hat{\xi}_n = e^{j\omega_n}$\;
    }{
        $\hat{\xi}_n = e^{j\text{sgn}(\omega_n) \frac{2\pi}{N}}$\;
    }
}

% Step 9: Compute PUC(z)
Compute $P_{UC}(z) = \prod_{n=1}^{Q-1} (1 - \hat{\xi}_n z^{-1}) = \sum_{n=0}^{P-1} c^*_n z^{-n}$\;

% Step 10: Define c
Define vector $c = [c_1, c_2, \ldots, c_N]$\;

% Step 11: Compute UC MVDR weight
Compute UC MVDR weight: $w_{UC} = \frac{c}{|c^H v_0|}$\;
\label{alg:uc}
\end{algorithm}

\end{document}